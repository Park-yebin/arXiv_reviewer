[{"figure_path": "https://arxiv.org/html/2407.05059/x1.png", "caption": "Figure 1: \nExamples of slice inconsistency and resolved outcomes.\nThis figure displays the coronal view of volumes synthesized by two 2D BBDMs trained on axial slices. The pure multi-slice 2D BBDM exhibits severe slice inconsistency, with noticeable discontinuities in both style and shape across slices. Our method produces slice-consistent volumes and can adjust the intensity histogram (i.e., style).", "description": "This figure illustrates the problem of slice inconsistency in 3D volumetric image generation using 2D Brownian Bridge Diffusion Models (BBDMs).  The leftmost image shows a source CT scan. The middle image demonstrates the output of a standard multi-slice 2D BBDM, which suffers from significant inconsistencies in both intensity (brightness and contrast) and shape (structural discontinuities) across different slices of the 3D volume.  The rightmost image showcases the results obtained using the proposed method which successfully addresses the slice inconsistency issue, resulting in a more consistent and accurate 3D MRI reconstruction.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2407.05059/x2.png", "caption": "Figure 2: \nTraining and sampling scheme of the proposed methods.\n(a) During the multi-slice BBDM training, a target histogram-based style key is injected into the U-Net.\n(b) Target volume sampling proceeds in the manner of the Predictor-Corrector method. During the co-prediction phase, multiple \u03f5\u03b8,ti,ksubscriptsuperscriptbold-italic-\u03f5\ud835\udc56\ud835\udc58\ud835\udf03\ud835\udc61\\bm{\\epsilon}^{i,k}_{\\theta,t}bold_italic_\u03f5 start_POSTSUPERSCRIPT italic_i , italic_k end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03b8 , italic_t end_POSTSUBSCRIPT are employed to establish connections among the predicted slices within \ud835\udc7f\u00aft\u22121subscriptbold-\u00af\ud835\udc7f\ud835\udc611\\bm{\\bar{X}}_{t-1}overbold_\u00af start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT. In the subsequent correction phase, the co-predicted volume is refined through a score-guided deterministic process.", "description": "Figure 2 illustrates the training and sampling process of the proposed method for 3D volumetric brain CT-to-MRI translation using a 2D Brownian Bridge Diffusion Model (BBDM). (a) shows the training phase where a multi-slice BBDM is trained by injecting a style key (derived from the MRI histogram) into the U-Net, which learns to map the style of the input CT slices to that of the target MRI slices.  The training process ensures style consistency across slices. (b) depicts the sampling phase, which uses a Predictor-Corrector approach to ensure both style and shape consistency in the generated 3D volume. The 'co-prediction' step combines predictions from multiple slices to create a preliminary prediction, and the 'correction' step refines this prediction to align with the desired style and shape using a score-guided deterministic process. This two-step approach ensures that the generated 3D MRI volume is consistent across slices and faithfully reflects the structure and style of the input CT volume.", "section": "2 Methods"}, {"figure_path": "https://arxiv.org/html/2407.05059/x3.png", "caption": "Figure 3: Visualization of the latent space and algorithm for ISTA sampling.\nThe trained U-Net produces inconsistent outputs for multi-slice inputs that include the it\u2062hsuperscript\ud835\udc56\ud835\udc61\u210ei^{th}italic_i start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT slice. The co-prediction unifies the direction of these independent inferences, while the correction aligns the co-predicted \ud835\udc99\u00aftisuperscriptsubscript\u00af\ud835\udc99\ud835\udc61\ud835\udc56\\bar{\\bm{x}}_{t}^{i}over\u00af start_ARG bold_italic_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT onto the manifold of \ud835\udc99tisubscriptsuperscript\ud835\udc99\ud835\udc56\ud835\udc61\\bm{x}^{i}_{t}bold_italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT.", "description": "Figure 3 illustrates the ISTA (Inter-slice Trajectory Alignment) sampling method, a key component of the proposed approach for generating slice-consistent 3D volumetric brain CT-to-MRI translations using a 2D Brownian Bridge Diffusion Model.  The figure shows how the model handles inconsistencies that arise from processing multiple slices independently.  Specifically, it highlights the 'co-prediction' step, where predictions from multiple slices are combined to create a unified direction for the next sampling step, and the 'correction' step, which ensures the resulting prediction aligns with the expected manifold, leading to coherent and consistent results across slices. This addresses the challenge of maintaining consistency in style and shape between individual slices in a 3D volume when using a 2D model.", "section": "Methods"}, {"figure_path": "https://arxiv.org/html/2407.05059/x4.png", "caption": "Figure 4: \nQualitative comparison with baselines (CT\u2192\u2192\\rightarrow\u2192MRI)", "description": "Figure 4 presents a qualitative comparison of brain CT to MRI translation results generated by various methods, including MaskGAN, Palette, RevGAN, ALDM, and the proposed method.  The figure visually showcases the performance of each method by displaying synthesized MRI images from a common source CT scan. This allows for a direct comparison of image quality and structural accuracy across the different approaches.  The goal is to demonstrate the superior performance of the proposed method in generating high-quality, slice-consistent 3D MRI images from CT scans.", "section": "3.1 Evaluations"}, {"figure_path": "https://arxiv.org/html/2407.05059/x5.png", "caption": "Table 3: Dataset details", "description": "This table details the characteristics of the two datasets used in the experiments: an in-house CT-MRI dataset and the publicly available BraTS2023 FLAIR-T1 MRI dataset.  For each dataset, the table provides the total number of images, the number of images used for training and testing, the dimensions (shape) of the image volumes, and the voxel size (resolution).", "section": "3 Experiments"}, {"figure_path": "https://arxiv.org/html/2407.05059/x6.png", "caption": "Table 4: Implementation details", "description": "Table 4 details the settings used for implementing the proposed method and baseline models. It lists the batch size, number of iterations, lambda (\u03bb) value, number of sampling steps, and GPU used for training the different models.  These details are crucial for reproducibility and understanding the computational resources required for training and evaluating each model.", "section": "3 Experiments"}, {"figure_path": "https://arxiv.org/html/2407.05059/x7.png", "caption": "Figure 5: Qualitative comparison with baselines (FLAIR\u2192\u2192\\rightarrow\u2192T1)", "description": "Figure 5 presents a qualitative comparison of brain MRI generation results from FLAIR (source) to T1 (target) images using different methods. It visually demonstrates the performance of various methods, including MaskGAN, Palette, RevGAN, ALDM, and the proposed approach. Each column showcases a sample of generated images using a different method. This allows for a direct visual comparison of image quality, level of detail, and overall similarity to the true T1 images. The figure provides a clear visualization of how well each model generates realistic and accurate brain MRIs from FLAIR input images.", "section": "3.1 Evaluations"}]